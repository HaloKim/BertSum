{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BertSum",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_r3RBbn79gc"
      },
      "source": [
        "# 은전한닢 로드\n",
        "\n",
        "https://github.com/SOMJANG/Mecab-ko-for-Google-Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9uvuAYG7vP2"
      },
      "source": [
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpfUqHb-7vNj"
      },
      "source": [
        "%cd Mecab-ko-for-Google-Colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cR4xNJk7vLG"
      },
      "source": [
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmG3vDN17vI0"
      },
      "source": [
        "from konlpy.tag import Mecab\n",
        "\n",
        "mecab = Mecab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj6idlCw7vGP"
      },
      "source": [
        "mecab.morphs('동해물과 백두산이 마르고 닳도록')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d366dbsVmyQh"
      },
      "source": [
        "# 패키지로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W2y29ZMYU7t"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensorboardx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4RRNgWeGGAd"
      },
      "source": [
        "# pyrouge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfmzjd9SnwVk"
      },
      "source": [
        "!pip install pyrouge --upgrade\n",
        "!pip install https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
        "!pip install pyrouge\n",
        "!pip show pyrouge\n",
        "!git clone https://github.com/andersjo/pyrouge.git\n",
        "from pyrouge import Rouge155\n",
        "!pyrouge_set_rouge_path 'pyrouge/tools/ROUGE-1.5.5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xaaB2uCn-8N"
      },
      "source": [
        "!sudo apt-get install libxml-parser-perl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9N7cryqoIQU"
      },
      "source": [
        "%%shell\n",
        "cd pyrouge/tools/ROUGE-1.5.5/data\n",
        "rm WordNet-2.0.exc.db # only if exist\n",
        "cd WordNet-2.0-Exceptions\n",
        "rm WordNet-2.0.exc.db # only if exist\n",
        "\n",
        "./buildExeptionDB.pl . exc WordNet-2.0.exc.db\n",
        "cd ../\n",
        "ln -s WordNet-2.0-Exceptions/WordNet-2.0.exc.db WordNet-2.0.exc.db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl7HMxYXFUPf"
      },
      "source": [
        "# Load the Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gYXSrkHFTwr"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/HaloKim/KorBertSum.git\n",
        "%cd /content/KorBertSum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i6OGXdMn8Ba"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWafHU5dbjlK"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "\n",
        "config = BertConfig.from_pretrained('bert-base-multilingual-cased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjHhHI9zm8Y9"
      },
      "source": [
        "# Data Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IWz6c4Ifjar"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/Study/DACON/235671_한국어 문서 추출요약 AI 경진대회_data/train.jsonl', 'r') as json_file:\n",
        "    json_list = list(json_file)\n",
        "result = []\n",
        "for json_str in json_list:\n",
        "    result.append(json.loads(json_str))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH7IQ9GtiZh1"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(result)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeukR_5HrlyH"
      },
      "source": [
        "test = df\n",
        "test['morphs'] = 0\n",
        "for i in range(len(test)):\n",
        "  arr = []\n",
        "  for j in test['article_original'][i]:\n",
        "    arr.append(' '.join(mecab.morphs(j)))\n",
        "  test['morphs'][i] = arr "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psok6XNpSPh4"
      },
      "source": [
        "test.to_csv('/content/drive/MyDrive/Colab_Notebooks/Study/BertSum-master/output.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxkjXDTrSV9M"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/Study/BertSum-master/output.csv')\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1FWGJcpIxRg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(test, test_size = 0.3)\n",
        "valid_set, test_set = train_test_split(test_set, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FhzVU6bODhm"
      },
      "source": [
        "import ast\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "list_dic = []\n",
        "for idx, row in train_set.iterrows():\n",
        "  raw = row['morphs']\n",
        "  target_idx = ast.literal_eval(row['extractive'])\n",
        "\n",
        "  sentences = raw.split(',')\n",
        "  src = [i.split(' ') for i in sentences]\n",
        "  tgt = [a for i,a in enumerate(src) if i in target_idx]\n",
        "  \n",
        "  mydict = {}\n",
        "  mydict['src'] = src\n",
        "  mydict['tgt'] = tgt\n",
        "  list_dic.append(mydict)\n",
        "        \n",
        "temp = []\n",
        "for i,a in enumerate(tqdm(list_dic)):\n",
        "  if (i+1)%6!=0:\n",
        "      temp.append(a)\n",
        "  else:\n",
        "      filename = 'korean.'+'train'+'.'+str(i//6)+'.json'\n",
        "      with open(os.getcwd()+'/json/'+filename, \"w\", encoding='utf8') as json_file:\n",
        "          json.dump(temp, json_file, ensure_ascii=False)\n",
        "      temp = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiGUznc2Jh5H"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csh4zkpPJpzu"
      },
      "source": [
        "try:\n",
        "  os.mkdir(os.getcwd()+'/json/val')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "list_dic = []\n",
        "for idx, row in valid_set.iterrows():\n",
        "        raw = row['morphs']\n",
        "        target_idx = ast.literal_eval(row['extractive'])\n",
        "\n",
        "        sentences = raw.split(',')\n",
        "        src = [i.split(' ') for i in sentences]\n",
        "        tgt = [a for i,a in enumerate(src) if i in target_idx]\n",
        "        \n",
        "        mydict = {}\n",
        "        mydict['src'] = src\n",
        "        mydict['tgt'] = tgt\n",
        "        list_dic.append(mydict)\n",
        "        \n",
        "temp = []\n",
        "for i,a in enumerate(tqdm(list_dic)):\n",
        "    \n",
        "    if (i+1)%6!=0:\n",
        "        temp.append(a)\n",
        "    else:\n",
        "        filename = 'korean.'+'valid'+'.'+str(i//6)+'.json'\n",
        "        with open(os.getcwd()+'/json/val/'+filename, \"w\", encoding='utf8') as json_file:\n",
        "            json.dump(temp, json_file, ensure_ascii=False)\n",
        "        temp = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTE25bv8Jp3A"
      },
      "source": [
        "try:\n",
        "  os.mkdir(os.getcwd()+'/json/test')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "list_dic = []\n",
        "for idx, row in valid_set.iterrows():\n",
        "        raw = row['morphs']\n",
        "        target_idx = ast.literal_eval(row['extractive'])\n",
        "\n",
        "        sentences = raw.split(',')\n",
        "        src = [i.split(' ') for i in sentences]\n",
        "        tgt = [a for i,a in enumerate(src) if i in target_idx]\n",
        "        \n",
        "        mydict = {}\n",
        "        mydict['src'] = src\n",
        "        mydict['tgt'] = tgt\n",
        "        list_dic.append(mydict)\n",
        "        \n",
        "temp = []\n",
        "for i,a in enumerate(tqdm(list_dic)):\n",
        "    \n",
        "    if (i+1)%6!=0:\n",
        "        temp.append(a)\n",
        "    else:\n",
        "        filename = 'korean.'+'test'+'.'+str(i//6)+'.json'\n",
        "        with open(os.getcwd()+'/json/test/'+filename, \"w\", encoding='utf8') as json_file:\n",
        "            json.dump(temp, json_file, ensure_ascii=False)\n",
        "        temp = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLQfbpzEKS6b"
      },
      "source": [
        "!python ./src/preprocess.py \\\n",
        "  -mode format_to_bert -raw_path ./json \\\n",
        "  -save_path ./bert_data \\\n",
        "  -log_file ./logs/log.log \\\n",
        "  -dataset train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGiQq9ejKI47"
      },
      "source": [
        "try:\n",
        "  os.mkdir(os.getcwd()+'/bert_data/val')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!python ./src/preprocess.py \\\n",
        "  -mode format_to_bert -raw_path ./json/val \\\n",
        "  -save_path ./bert_data/val \\\n",
        "  -log_file ./logs/val_log.log \\\n",
        "  -dataset valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDhVi3KQJ3_c"
      },
      "source": [
        "try:\n",
        "  os.mkdir(os.getcwd()+'/bert_data/test')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!python ./src/preprocess.py \\\n",
        "  -mode format_to_bert -raw_path ./json/test \\\n",
        "  -save_path ./bert_data/test \\\n",
        "  -log_file ./logs/test_log.log \\\n",
        "  -dataset test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa5vcawrGlbo"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHnvBZO-cwbf"
      },
      "source": [
        "!python ./src/train.py \\\n",
        "  -mode train -encoder classifier -dropout 0.1 \\\n",
        "  -bert_data_path ./bert_data/korean \\\n",
        "  -model_path ./models/bert_classifier \\\n",
        "  -lr 2e-3 -visible_gpus 0 -gpu_ranks 0 -world_size 1 -report_every 100 \\\n",
        "  -save_checkpoint_steps 1000 -batch_size 1000 -decay_method noam -log_file ./logs/log.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWd-qpB_GoeE"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XV4tywmcT_P"
      },
      "source": [
        "!python ./src/train.py \\\n",
        "  -mode validate \\\n",
        "  -bert_data_path ./bert_data/val/korean \\\n",
        "  -model_path ./models/bert_classifier \\\n",
        "  -visible_gpus 0 -gpu_ranks 0 -batch_size 1000 \\\n",
        "  -log_file ./logs/val_log.log \\\n",
        "  -result_path ./results/val \\\n",
        "  -test_from ./models/bert_classifier/model_step_1000.pt \\\n",
        "  -temp_dir ./temp \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw_x2sIFnGOP"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nisU6_FZEGfx"
      },
      "source": [
        "!python ./src/train.py \\\n",
        "  -mode test \\\n",
        "  -bert_data_path ./bert_data/test/korean \\\n",
        "  -model_path ./models/bert_classifier \\\n",
        "  -visible_gpus 0 -gpu_ranks 0 -batch_size 1000 \\\n",
        "  -log_file ./logs/log.log \\\n",
        "  -result_path ./results \\\n",
        "  -test_from ./models/bert_classifier/model_step_10000.pt \\\n",
        "  -temp_dir ./temp \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UcXM_1ACwqo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}